{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python libraries\n",
    "import numpy as np    # numpy is the fundamental package for scientific computing with Python, such linear algebra, array...\n",
    "import matplotlib.pyplot as plt      # matplotlib is a Python 2D plotting library which produces publication quality figures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    \"\"\"\n",
    "    This lab implements a Logistic Regression Classifier.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        \"\"\"\n",
    "        Initializes the parameters of the logistic regression classifer to \n",
    "        random values.\n",
    "        \n",
    "        args:\n",
    "            input_dim: Number of dimensions of the input data\n",
    "            hidden_dim: Number of nodes in the hidden layer\n",
    "            output_dim: Number of classes\n",
    "        \"\"\"\n",
    "        self.W1 = np.random.randn(input_dim, hidden_dim) / np.sqrt(input_dim)       \n",
    "        self.W2 = np.random.randn(hidden_dim, output_dim) / np.sqrt(hidden_dim)\n",
    "        self.bias1 = np.zeros((1, hidden_dim))\n",
    "        self.bias2 = np.zeros((1, output_dim))\n",
    "        \n",
    "    #--------------------------------------------------------------------------\n",
    "    \n",
    "    def compute_cost(self,X, y):\n",
    "        \"\"\"\n",
    "        Computes the total cost on the dataset.\n",
    "        \n",
    "        args:\n",
    "            X: Data array\n",
    "            y: Labels corresponding to input data\n",
    "        \n",
    "        returns:\n",
    "            cost: average cost per data sample\n",
    "        \"\"\"\n",
    "        num_examples = np.shape(X)[0]\n",
    "        z2 = np.dot(X,self.W1) + self.bias1 #z2 1000X4\n",
    "        a2 = np.tanh(z2) #1000X4\n",
    "        z3 = np.dot(a2,self.W2) + self.bias2 #z3 1000X2\n",
    "        exp_z3 = np.exp(z3) #1000X2\n",
    "        softmax_scores = exp_z3 / (exp_z3 + 1) #a3 1000X2\n",
    "        \n",
    "        one_hot_y = np.zeros((num_examples,np.max(y)+1))\n",
    "        logloss = np.zeros((num_examples,))        \n",
    "        for i in range(np.shape(X)[0]):\n",
    "            one_hot_y[i,y[i]] = 1\n",
    "            logloss[i] = -np.sum(np.log(softmax_scores[i,:]) * one_hot_y[i,:])\n",
    "        data_loss = np.sum(logloss)\n",
    "        return 1./num_examples * data_loss\n",
    "\n",
    "    \n",
    "    #--------------------------------------------------------------------------\n",
    " \n",
    "    def predict(self,X):\n",
    "        \"\"\"\n",
    "        Makes a prediction based on current model parameters.\n",
    "        \n",
    "        args:\n",
    "            X: Data array\n",
    "            \n",
    "        returns:\n",
    "            predictions: array of predicted labels\n",
    "        \"\"\"\n",
    "        z2 = np.dot(X,self.W1) + self.bias1 #h ---> z2\n",
    "        a2 = np.tanh(z2)\n",
    "#         exp_h = np.exp(h)\n",
    "#         hidden_scores = exp_h / (exp_h + 1) ----> a2\n",
    "        z3 = np.dot(a2,self.W2) + self.bias2\n",
    "        exp_z3 = np.exp(z3)\n",
    "        softmax_scores = exp_z3 / (exp_z3 + 1)\n",
    "        predictions = np.argmax(softmax_scores, axis = 1)\n",
    "        return predictions\n",
    "        \n",
    "    #--------------------------------------------------------------------------\n",
    "    # TODO: implement logistic regression using gradient descent \n",
    "    #--------------------------------------------------------------------------\n",
    "    def fit(self,X,y,num_epochs,alpha=0.01):\n",
    "    \n",
    "        #Learns model parameters to fit the data.\n",
    "#         X = a1 1000X2\n",
    "#         W1 = 2X4\n",
    "#         W2 = 4X2\n",
    "\n",
    "        for epoch in range(0, num_epochs):\n",
    "\n",
    "            # Forward propagation\n",
    "            z2 = np.dot(X,self.W1) + self.bias1 #z2 1000X4\n",
    "            a2 = np.tanh(z2) #1000X4\n",
    "            z3 = np.dot(a2,self.W2) + self.bias2 #z3 1000X2\n",
    "            exp_z3 = np.exp(z3) #1000X2\n",
    "            softmax_scores = exp_z3 / (exp_z3 + 1) #a3 1000X2\n",
    "        \n",
    "            # Backpropagation\n",
    "            delta3 = np.zeros_like(softmax_scores) #1000X2\n",
    "            one_hot_y = np.zeros_like(softmax_scores) #1000X2\n",
    "            for i in range(X.shape[0]):\n",
    "                one_hot_y[i,y[i]] = 1\n",
    "            delta3 = softmax_scores - one_hot_y #delta3 1000X2\n",
    "            g_dash = 1-(np.power(a2,2))\n",
    "            delta2 = np.multiply(np.dot(delta3,self.W2.T),g_dash) #delta2\n",
    "            \n",
    "            # Compute gradients of model parameters\n",
    "            dW2 = np.dot(a2.T,delta3)\n",
    "            dW1 = np.dot(X.T,delta2)\n",
    "            dbias2 = np.sum(delta3, axis=0)\n",
    "            dbias1 = np.sum(delta2, axis=0)\n",
    "\n",
    "#             # add L2 regularization\n",
    "#             dW2 += L2_reg * self.W2\n",
    "#             dW1 += L2_reg * self.W1\n",
    "            \n",
    "            # Gradient descent parameter update\n",
    "            self.W2 -= alpha * dW2\n",
    "            self.bias2 -= alpha * dbias2  \n",
    "            self.W1 -= alpha * dW1\n",
    "            self.bias1 -= alpha * dbias1   \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(model, X, y):\n",
    "    \"\"\" \n",
    "    Function to print the decision boundary given by model.\n",
    "    \n",
    "    args:\n",
    "        model: model, whose parameters are used to plot the decision boundary.\n",
    "        X: input data\n",
    "        y: input labels\n",
    "    \"\"\"\n",
    "    \n",
    "    x1_array, x2_array = np.meshgrid(np.arange(-4, 4, 0.01), np.arange(-4, 4, 0.01))\n",
    "    grid_coordinates = np.c_[x1_array.ravel(), x2_array.ravel()]\n",
    "    Z = model.predict(grid_coordinates)\n",
    "    Z = Z.reshape(x1_array.shape)\n",
    "    plt.contourf(x1_array, x2_array, Z, cmap=plt.cm.bwr)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.bwr)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Load data\n",
    "X = np.genfromtxt('P1_DATA/DATA/Digit_X_train.csv', delimiter=',') #https://docs.scipy.org/doc/numpy/reference/generated/numpy.genfromtxt.html\n",
    "y = np.genfromtxt('P1_DATA/DATA/Digit_y_train.csv', delimiter=',').astype(np.int64)\n",
    "# X[0:10]\n",
    "# np.shape(X)[0]\n",
    "# np.max(y) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAFJlJREFUeJzt3X2QHPV95/H3V/soCQkJWGzQA+LJDnKKO+KFcyrBdgKOhRMjx3FicXVV3CVVXC7mYsdJzrpyjhByd36qPDg5LjZxXOe44pOxE8dKgoPtOE7su0C0YIwRHGElFLQIg3iQQI/79L0/pleM1rPa2dnZbW3v+1U1tdPdv+n5bG/vR62e3pnITCRJ1bKk7ACSpPaz3CWpgix3Saogy12SKshyl6QKstwlqYIsd0mqIMtdkirIcpekCuos64nPOeec3LBhQ1lPL0kL0n333fdsZvZNN660ct+wYQMDAwNlPb0kLUgR8c/NjPO0jCRVkOUuSRVkuUtSBVnuklRBlrskVZDlLkkVZLlLUgVZ7pJUQZa7JFWQ5S5JFVTa2w9Ip51MGB6GkRHo6oLubogoO5XUEstdAhgfh2eegdHRl+d1dUFfHyzxP7haeNxrJYAXXqgdsWe+fBsehoMHy04mtcRylzLhyJHGyw4fnt8sUptY7tKpZJadQGqJ5S5FQE9P42W9vfObRWoTy10CWL26VvITV8dE1F5IXb263FxSi7xaRoLalTHnnVc7xz4yUrsMcvlyr5TRgmW5SxM6OmDlyrJTSG3hYYkkVZDlLkkVZLlLUgVZ7pJUQZa7JFWQ5S5JFWS5S1IFNVXuEbEpIh6NiMGI2HqKce+IiIyI/vZFlCTN1LTlHhEdwO3AdcBG4IaI2Nhg3ArgF4F72x1SkjQzzRy5XwUMZubuzBwGtgGbG4z7TeDDwLE25pMktaCZcl8D7K2bHirmnRARVwDrMvMv25hNktSiZsq90YdInniT64hYAvwO8MvTrijipogYiIiB/fv3N59SkjQjzZT7ELCubnotsK9uegXw/cDXI2IP8Dpge6MXVTPzjszsz8z+vr6+1lNLkk6pmXLfAVwaERdGRDewBdg+sTAzD2bmOZm5ITM3APcA12fmwJwkliRNa9pyz8xR4GbgbuAR4M7M3BkRt0XE9XMdUJI0c029n3tm3gXcNWneLVOMfePsY0mSZsO/UJWkCrLcJamC/Jg9qXBw32HGDh6it2uMoyMddK1ewcpXLis7ltQSy10CXtj7EivGDtKxPImApd1jjB17ngNPjrNqzRllx5NmzNMyEtB17CU6O2rFDhBBbfrQS+UGk1pkuWvRy7FxlveMNVy2ond0ntNI7WG5S8DoWKN32YDhUX9FtDC552rRi44lPH+sl9FJB++jY8GLo0vLCSXNkuUuAee+6iyeP9LL2DiMjAWjY/D80V76LllVdjSpJV4tI1E7ej93Yx8jR0c5fniE3hVdnNvjr4cWLvdeqU7X0k66lvproYXP0zKSVEGWuyRVkOUuSRVkuUtSBVnuklRBlrskVZDlLkkVZLlLUgVZ7pJUQZa7JFWQ5S5JFWS5S1IFWe6SVEGWuyRVkOUuSRVkuUtSBVnuklRBlrtUZ89jx/n6Xx9l7+PDZUeRZsXPE5OAY0fG+eAHxjl4qLs24244+8wR/tPWDrp7PQbSwuNeKwG//9FRDh7qAOLE7bmDnXz8f46UnExqjeWuRW98dJx9z3RRK/V6we693WVEkmbNcteiNz5edgKp/Sx3LXqd3Uvo6swGS5LebptfC1NT5R4RmyLi0YgYjIitDZb/fER8JyIeiIhvRsTG9keV5s7bf2IYyOLGia/vfLtXzWhhmvZqmYjoAG4H3gQMATsiYntmPlw37DOZ+bFi/PXAbwOb5iCvNCde94Zezlx9nD//4hIOvNjB2avGePtPjnPJxqVlR5Na0sylkFcBg5m5GyAitgGbgRPlnpkv1o1fzsuHP9KCcdnlPVx2+cSUZyy1sDVT7muAvXXTQ8C/mjwoIt4FvBfoBn60LekkSS1p5vBk8vVh0ODIPDNvz8yLgfcBv9ZwRRE3RcRARAzs379/ZkklSU1rptyHgHV102uBfacYvw14W6MFmXlHZvZnZn9fX1/zKSVJM9JMue8ALo2ICyOiG9gCbK8fEBGX1k3+OPBY+yJKkmZq2nPumTkaETcDdwMdwCczc2dE3AYMZOZ24OaIuBYYAV4AbpzL0JKkU2vqjcMy8y7grknzbqm7/+4255IkzYLXe0lSBVnuklRBlrskVZDlLkkVZLlLUgVZ7pJUQZa7JFWQ5S5JFWS5S1IFWe6SVEGWuyRVkOUuSRXU1BuHSYvBrgdf5Fv3B999ros1fcNc0Q8bNq4sO5bUEstdAh76Py/w6S+eydhYMDYe7Hmqh3/cmdz4jgN835Wryo4nzZinZSTgy99YxvDIEsbGa58qOTYWHBsOvvaN3pKTSa2x3LXojRwZYejp7gZLgt1P9sx7HqkdLHctehHQ2fk9n/kOQE/3+DynkdrDctei17m0i/7LDtPZcXKRd3WOc9VrDpeUSpody10CNm3u4ZJ1x+nqHKe3e5zOjnEuu/AYb3rr0rKjSS3xahkJWHl2N//+3fDYtw5y4NkxznpFJxdf7mWQWrgsd6nOpVecWXYEqS08LSNJFWS5S1IFWe6SVEGWuyRVkOUuSRVkuUtSBVnuklRBlrskVZDlLkkVZLlLUgVZ7pJUQZa7JFVQU+UeEZsi4tGIGIyIrQ2WvzciHo6IByPibyLigvZHlSQ1a9pyj4gO4HbgOmAjcENEbJw07FtAf2ZeDnwe+HC7g0qSmtfMkftVwGBm7s7MYWAbsLl+QGb+bWYeKSbvAda2N6YkaSaaKfc1wN666aFi3lR+DvjSbEJJkmanmQ/riAbzGn6acET8G6AfeMMUy28CbgJYv359kxElSTPVzJH7ELCubnotsG/yoIi4Fng/cH1mHm+0osy8IzP7M7O/r6+vlbzSnNr14Ev82acOsufhQ2VHkWalmSP3HcClEXEh8CSwBfjX9QMi4grg48CmzHym7SmlOfbic8f5zQ90MTp2BgDfeAC6u8b4jV8bo3dld8nppJmb9sg9M0eBm4G7gUeAOzNzZ0TcFhHXF8M+ApwBfC4iHoiI7XOWWJoD//1DnYyOBbWzkLXb8MgS/usH/FMQLUxNfUB2Zt4F3DVp3i11969tcy5p3hx7cZjjI11878tLweFjHWVEkmbNwxItesPHxsuOILWd5a5Fb+W5vWVHkNrOcpeAV551nJOv8E0gueAVR0tKJM2O5S4B7/svvVzwyqNMlDrAJWuP8J6ty0rNJbWqqRdUpcXgPe+bXOTLS8khtYNH7pJUQZa7JFWQ5S5JFWS5S1IFWe6SVEGWuyRVkOUuSRVkuUtSBVnuklRBlrskVZDlLkkVZLlLUgVZ7pJUQZa7JFWQ5S5JFWS5S1IFWe6SVEGWuyRVkB+zJxW++hcHePWaY5y5fJwDh5awa/8yfmTTyrJjSS2x3CXga188wDVXvARABKxYOsa6voN8+Qvj/NhPrio5nTRznpaRgB++/BBQK/b6r1cX86WFxnLXorfviSN0deSJQp8QAb1dWU4oaZYsdy16XTH9GGmhsdy16PWtW8bR4SAnHaRnwqGjHeWEkmbJcpeAbzy0nPGsFfrEbWwc7v2nZWVHk1ri1TIS8Oa3rWbfEz3s332Us1eOsv+FTta+ainXvtVy18JkuUuF89cv4/z1tTJfW3IWabY8LSNJFWS5S1IFNVXuEbEpIh6NiMGI2Npg+esj4v6IGI2Id7Q/piRpJqYt94joAG4HrgM2AjdExMZJw54A/i3wmXYHlCTNXDMvqF4FDGbmboCI2AZsBh6eGJCZe4pl43OQUZI0Q82cllkD7K2bHirmSZJOU82Ue6M/zm7pDTci4qaIGIiIgf3797eyCklSE5op9yFgXd30WmBfK0+WmXdkZn9m9vf19bWyCklSE5op9x3ApRFxYUR0A1uA7XMbS5I0G9OWe2aOAjcDdwOPAHdm5s6IuC0irgeIiCsjYgj4aeDjEbFzLkNLkk6tqbcfyMy7gLsmzbul7v4O/IttSTpt+BeqklRBlrskVZDlLkkVZLlLUgVZ7pJUQZa7JFWQ5S5N8uTDz5YdQZo1y10q7L3vKfKJvZx/xlHyib08fu93y44ktcxyl4Ch+55ibd8oEZy4bThvhF33PF12NKkllrsErCmKvV4EXHT+cDmBpFmy3LXoPbZjqOwIUttZ7lr0Lr3St0VS9VjuErD3mU5y0kfQZMKuJ3vKCSTNkuUuAev7z+OJp7vI5MRt175uLvnBc8uOJrWkqbf8lRaDC6585UnTl6wvKYjUBh65S1IFWe6SVEGWuyRVkOUuSRVkuUtSBVnuklRBlrskVZDlLkkVZLlLUgVZ7pJUQZa7JFWQ5S5JFWS5S1IFWe6SVEGWuyRVkOUuSRVkuUtSBVnuklRBTX3MXkRsAj4KdACfyMwPTlreA/wx8FrgOeCdmbmnvVGlufWJ13+Uq69eRc/yDo4eGuPOv3qcX//2rWXHkloybblHRAdwO/AmYAjYERHbM/PhumE/B7yQmZdExBbgQ8A75yKwNBe++auf4y3/7ccZP+dcsqubFSMj3HTNE3z1lz7Htb/z02XHk2asmdMyVwGDmbk7M4eBbcDmSWM2A58q7n8euCYion0xpbl18eWrGDt/PXnGSujpJc9YwegFF7Pxst6yo0ktaabc1wB766aHinkNx2TmKHAQOLsdAaW59hv/4lZGf+gN0N198oKeXsZf/8ZSMkmz1Uy5NzoCzxbGEBE3RcRARAzs37+/mXzS/FjS+Fchl3TMcxCpPZop9yFgXd30WmDfVGMiohM4E3h+8ooy847M7M/M/r6+vtYSS23269++lc6Bf4DR0ZMXjIzQec83ywklzVIz5b4DuDQiLoyIbmALsH3SmO3AjcX9dwBfy8zvOXKXTldDA0MsOfAccfgQAHH4JZY89wx7dh4oOZnUmmmvlsnM0Yi4Gbib2qWQn8zMnRFxGzCQmduBPwI+HRGD1I7Yt8xlaKndrvzgDXzpP97Jq/uO0716GcefP8JDQ51s/sMbyo4mtSTKOsDu7+/PgYGBUp5bkhaqiLgvM/unG+dfqEpSBVnuklRBlrskVZDlLkkVZLlLUgVZ7pJUQZa7JFWQ5S5JFWS5S1IFWe6SVEGWuyRVUGnvLRMR+4F/LuXJm3MO8GzZIZq0ULKas/0WStaFkhNO/6wXZOa075leWrmf7iJioJk35zkdLJSs5my/hZJ1oeSEhZX1VDwtI0kVZLlLUgVZ7lO7o+wAM7BQspqz/RZK1oWSExZW1il5zl2SKsgjd0mqoEVR7hFxVkR8JSIeK76unmLcjcWYxyLixrr5r42I70TEYET8XkREMf+zEfFAcdsTEQ8U8zdExNG6ZR8rOeetEfFkXZ631D3mPxfjH42INzeTc46zfiQi/l9EPBgRX4iIVcX8GW3TiNhUfE+DEbG1wfKe4uc3GBH3RsSG6bbJVOssPjz+3uJ7/GzxQfLNbse25oyIdRHxtxHxSETsjIh3142fcj8oI2sxf0+xHzwQEQN185vav+YjZ0S8um6bPRARL0bEe4pls9qmcyozK38DPgxsLe5vBT7UYMxZwO7i6+ri/upi2T8CPwgE8CXgugaP/y3gluL+BuCh0yUncCvwKw3WtRH4NtADXAjsAjpKzvpjQGdx/0MT653JNqX2Qe67gIuA7uJ73DhpzC8AHyvubwE+e6ptcqp1AncCW4r7HwP+Q4k5zwN+oBizAvinupwN94OyshbL9gDntLJ/zWfOSev/LrVrzWe1Tef6tiiO3IHNwKeK+58C3tZgzJuBr2Tm85n5AvAVYFNEnAeszMx/yNpP848nP7446vwZ4H+fzjmneL5tmXk8Mx8HBoGrysyamV/OzNHi8fcAa5vMU+8qYDAzd2fmMLCtyDtV/s8D1xQ/x6m2ScN1Fo/50WIdp9oW85IzM5/KzPsBMvMl4BFgTZN55jXrNM/XzP5VRs5rgF2ZeTr/ASawSE7LAK/IzKcAiq/nNhizBthbNz1UzFtT3J88v97VwNOZ+VjdvAsj4lsR8XcRcfVpkPPm4lTHJ+v+izvVusrOOuFnqR3VT2h2mzbzfZ0YU/xjchA4e5rMjeafDRyo+wdpJttwLnKeUJxuuAK4t252o/2gzKwJfDki7ouIm+rGNLN/zWfOCVv43oO4VrfpnKpMuUfEVyPioQa3yf9qT7mKBvPyFPPr3cDJP/CngPWZeQXwXuAzEbGyxJx/AFwM/Msi229Nsy5KzDrx3O8HRoE/KWZNuU1n8LyzyTab/WMqc5Gz9qCIM4A/Bd6TmS8Ws6faD8rM+kOZ+QPAdcC7IuL1M8jUyFxu027geuBzdctns03nVGfZAdolM6+dallEPB0R52XmU8UpgWcaDBsC3lg3vRb4ejF/7aT5++rW3Qm8HXhtXZbjwPHi/n0RsQt4FTBQRs7MfLruOf4Q+Mu6da2b6nsrcZveCPwEcE1x2uaU23SK553y+5o0Zqj4GZ4JPD/NYxvNfxZYFRGdxVFgo+eaypzkjIguasX+J5n5ZxMDTrEflJY1Mye+PhMRX6B2GuTvgWb2r3nLWbgOuL9+O85ym86tsk/6z8cN+Agnvzjz4QZjzgIep/bC3+ri/lnFsh3A63j5xb+31D1uE/B3k9bVx8svGF0EPDmxrjJyAufVPf6XqJ1XBHgNJ7+AtJvmX1Cdq6ybgIeBvla3KbWDlt3F9zTxotprJo15Fye/qHbnqbbJqdZJ7Uiu/gXVX2hyG85FzqD2GsbvNni+hvtBiVmXAyuKMcuB/wtsanb/mq+cdY/bBvy7dm3Tub6VHmBevsna+bS/AR4rvk4UTD/wibpxP0vtRZTB+h9iMe4haq+e/w+KP/4qlv0v4OcnPd9PATuLHeV+4K1l5gQ+DXwHeBDYPmmHfH8x/lEaXAVUQtZBauc9HyhuE7+EM9qmwFuoXSmyC3h/Me824Prifi+1Uh6kduXORdNtk0brLOZfVKxjsFhnzwy2Y1tzAj9M7VTCg3XbcOIfzin3g5KyXlT8PL9d/Gzrt2nD/auMnMX8ZcBzwJmTnmtW23Qub/6FqiRVUGVeUJUkvcxyl6QKstwlqYIsd0mqIMtdkirIcpekCrLcJamCLHdJqqD/D5TmXSyOrPxtAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a5e9306438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#2. plot data\n",
    "plt.scatter(X[:,0], X[:,1], c=y, cmap=plt.cm.bwr) #http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.scatter\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Initialize model\n",
    "input_dim = np.shape(X)[1]\n",
    "output_dim = np.max(y) + 1\n",
    "hidden_dim = 20\n",
    "logreg = LogisticRegression(input_dim, hidden_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Plot decision boundary\n",
    "# plot_decision_boundary(logreg, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Classification Model\n",
    "**Classification** tries to predict, which of a small set of classes, a sample in a population belongs to. Mathematically, the aim is to find $y$, a **label** based on knowing a feature vector $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5. Train the model\n",
    "logreg.fit(X,y,1000,alpha=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Plot decision boundary after trainning\n",
    "# plot_decision_boundary(logreg, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY:  1.0\n",
      "CONFUSION MATRIX: \n",
      " [[90.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0. 91.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. 91.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. 92.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0. 89.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0. 91.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0. 90.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0. 90.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0. 86.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0. 88.]]\n"
     ]
    }
   ],
   "source": [
    "#7. ompute accuracy and confusion matrix\n",
    "acc = 0\n",
    "y_pred = logreg.predict(X)\n",
    "con_mat = np.zeros((output_dim, output_dim))\n",
    "for i in range(len(y_pred)):\n",
    "    con_mat[y_pred[i], y[i]] += 1\n",
    "    if y[i] == y_pred[i]:\n",
    "        acc += 1\n",
    "acc = acc/len(y_pred)\n",
    "print ('ACCURACY: ', acc)\n",
    "print ('CONFUSION MATRIX: \\n', con_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016690559917196188\n"
     ]
    }
   ],
   "source": [
    "#5. compute cost\n",
    "cost = logreg.compute_cost(X,y)\n",
    "print (cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
